{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Program - fetch tweet based on search term, create training data, ML model to NER bird names.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahaanirbannew/spacy-custom-NER-bird-names/blob/main/Program_fetch_tweet_based_on_search_term%2C_create_training_data%2C_ML_model_to_NER_bird_names.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Function definitions"
      ],
      "metadata": {
        "id": "B6doKl7BNvIr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "mZlnmywMkrsR"
      },
      "outputs": [],
      "source": [
        "def what_search_term():\n",
        "  search_term = \"indiAves\"        ## CHANGE THIS. \n",
        "  return search_term\n",
        "  \n",
        "\n",
        "import tweepy\n",
        "import time\n",
        "import pickle\n",
        "import csv\n",
        "import datetime \n",
        "from datetime import datetime \n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "import pandas as pd \n",
        "import re\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "from spacy.util import filter_spans\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "\n",
        "def connect_to_google_drive():\n",
        "  drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "def extract_model_best_from_archive():\n",
        "  file_name = \"/content/model-best.zip\"\n",
        "  with ZipFile(file_name, 'r') as zip:\n",
        "    zip.extractall(\"/content/model-best\")\n",
        "\n",
        "def is_GPU_on():\n",
        "  if tf.test.gpu_device_name() == \"\": \n",
        "    return False\n",
        "  return True \n",
        "\n",
        "def create_twitter_app_obj():\n",
        "  consumer_key = \"iPaIdR8GRI59yTJMs0Es0dIBN\"\n",
        "  consumer_secret = \"pLadg3UaLeK3yKDujRMChRN3p8hUDBOjBsuOBy8j8ERr4zz1vs\"\n",
        "  access_token = \"39085479-AabHt6bmFSbClDfUZuHjModYPAxVlOxHeMA79UyVt\"\n",
        "  access_token_secret = \"3IqXDISfqg14wzMNNn2AX4KYG9Wfkltt21QxKasE4YNnG\"\n",
        "  # Creating the authentication object\n",
        "  auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "  # Setting your access token and secret\n",
        "  auth.set_access_token(access_token, access_token_secret)\n",
        "  # Creating the API object while passing in auth information\n",
        "\n",
        "  try:\n",
        "    api = tweepy.API(auth) \n",
        "    return api\n",
        "  except:\n",
        "    print(\"Error: Error making the Twitter Object.\")\n",
        "    return 0\n",
        "\n",
        "def get_google_drive_folder_path():\n",
        "  path = \"/content/drive/My Drive/IndiAves/\" \n",
        "  return path \n",
        "\n",
        "def get_since_id(path,search_word):\n",
        "  file = open(path+\"since_id\",'rb')\n",
        "  try:\n",
        "    since_id_data = pickle.load(file)\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "    return 0\n",
        "  try: \n",
        "    since_id = since_id_data[search_word]\n",
        "    return since_id\n",
        "  except:\n",
        "    print(\"Info: This looks like a new search.\")\n",
        "    return 0\n",
        "\n",
        "def load_all_birds_list(path):\n",
        "  file = open(path+\"bird_list_df\",'rb')\n",
        "  bird_list_df = pickle.load(file)\n",
        "  try: \n",
        "    return bird_list_df\n",
        "  except:\n",
        "    print(\"Error: No bird list found.\")\n",
        "    return 0\n",
        "  \n",
        "def load_training_data(path):\n",
        "  file = open(path+\"training_data\",'rb')\n",
        "  training_data = pickle.load(file)\n",
        "  try: \n",
        "    return training_data\n",
        "  except:\n",
        "    print(\"Error: No training data found.\")\n",
        "    return 0\n",
        "\n",
        "def load_nlp_model_():\n",
        "  import spacy\n",
        "  #nlp = spacy.load(\"en_core_web_sm\")\n",
        "  nlp = spacy.blank(\"en\")\n",
        "  print(nlp.pipe_names)\n",
        "  return nlp\n",
        "\n",
        "def create_doc_bin(training_data,nlp):\n",
        "  from spacy.tokens import DocBin\n",
        "  from tqdm import tqdm\n",
        "  from spacy.util import filter_spans\n",
        "  doc_bin = DocBin()\n",
        "  for training_example  in tqdm(training_data['annotations']): \n",
        "    text = training_example['text']\n",
        "    labels = training_example['entities']\n",
        "    doc = nlp.make_doc(text) \n",
        "    ents = []\n",
        "    for start, end, label in labels:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        #if span is None:\n",
        "        #    print(\"Skipping entity\")\n",
        "        #else:\n",
        "        #    ents.append(span)\n",
        "        if span is not None:\n",
        "          ents.append(span)\n",
        "    filtered_ents = filter_spans(ents)\n",
        "    doc.ents = filtered_ents \n",
        "    doc_bin.add(doc)\n",
        "  doc_bin.to_disk(\"training_data.spacy\") # save the docbin object\n",
        "\n",
        "def export_training_data(training_data,path):\n",
        "  filepath = open(path+\"training_data\",'wb') \n",
        "  pickle.dump(training_data, filepath)                     \n",
        "  filepath.close()\n",
        "  print(len(training_data), \"examples of training data saved.\") \n",
        "\n",
        "def initialisation():\n",
        "  !pip install tweet-preprocessor\n",
        "  !python -m spacy download en_core_web_sm\n",
        "  !pip install spacy[transformers]\n",
        "\n",
        "def import_base_config_file(google_drive_folder_path):\n",
        "  shutil.copyfile(google_drive_folder_path+\"base_config.cfg\", \"/content/base_config.cfg\")\n",
        "\n",
        "def basic_preprocess(tweet):\n",
        "  import preprocessor as p\n",
        "  p.set_options(p.OPT.EMOJI, p.OPT.MENTION, p.OPT.URL, p.OPT.SMILEY, p.OPT.NUMBER,p.OPT.HASHTAG)\n",
        "  tweet = tweet.lower()\n",
        "  tweet = tweet.replace(\"\\n\",\" \")  \n",
        "  tweet = tweet.replace(\"\\\\n\",\" \")\n",
        "  tweet = tweet.replace(\"'\",\"\")\n",
        "  tweet = tweet[1:] \n",
        "  tweet = p.clean(tweet)\n",
        "  tweet = re.sub(r'[^\\w\\s]', ' ', tweet)\n",
        "  tweet = re.sub(r' x..', '', tweet)\n",
        "  tweet = re.sub(r' +', ' ', tweet) #' +', ' '\n",
        "  #tweet = re.sub(r' n. ', '', tweet) \n",
        "  tweet = tweet.replace(\"x9c\",\"\")\n",
        "  tweet = tweet.strip()\n",
        "  return tweet\n",
        "\n",
        "def preprocess_tweets_arr_batch(tweets):\n",
        "  new_tweets_ = []\n",
        "  for tweet in tweets:\n",
        "    tweet = basic_preprocess(tweet)\n",
        "    if len(tweet) > 1:\n",
        "      new_tweets_.append(tweet)\n",
        "  return new_tweets_\n",
        "\n",
        "def add_to_database(api, search_word, ext_path, since_id):\n",
        "  new_search = \"#\" +search_word + \" -filter:retweets\" \n",
        "  count = 0\n",
        "  csvFile = open(ext_path+search_word+'.csv', 'a')\n",
        "  csvFile2 = open('/content/temp_.csv', 'w') \n",
        "\n",
        "  csvWriter = csv.writer(csvFile)\n",
        "  csvWriter2 = csv.writer(csvFile2)\n",
        "\n",
        "  for tweet in tweepy.Cursor(api.search,q=new_search,count=100,\n",
        "                            lang=\"en\",\n",
        "                            since_id=since_id, tweet_mode=\"extended\").items(): \n",
        "    if tweet.id > since_id:\n",
        "      since_id = tweet.id\n",
        "    \n",
        "    media_url=\"\"\n",
        "    if tweet.entities.get('media', []): media_url = tweet.entities.get('media', [])[0]['media_url']\n",
        "\n",
        "    hashtags = []\n",
        "    for tag in tweet.entities[\"hashtags\"]:\n",
        "      hashtags.append(tag[\"text\"]) \n",
        "    \n",
        "    csvWriter.writerow([tweet.created_at, tweet.id, tweet.user.screen_name.encode('utf-8'), tweet.user.location.encode('utf-8'), tweet.full_text.encode('utf-8'), media_url, hashtags])\n",
        "    csvWriter2.writerow([tweet.created_at, tweet.id, tweet.user.screen_name.encode('utf-8'), tweet.user.location.encode('utf-8'), tweet.full_text.encode('utf-8'), media_url, hashtags])\n",
        "    count +=1\n",
        "  print(datetime.now(),count, \"tweets retrieved.\")\n",
        "  return since_id \n",
        "\n",
        "def update_since_id(since_id, path,search_word):\n",
        "  filepath = open(path+\"since_id\",'rb')\n",
        "  since_id_data = pickle.load(filepath)\n",
        "  since_id_data[search_word]=since_id\n",
        "  filepath = open(path+\"since_id\",'wb') \n",
        "  pickle.dump(since_id_data, filepath)                     \n",
        "  filepath.close()\n",
        "\n",
        "def train_model():\n",
        "  !python -m spacy init fill-config base_config.cfg config.cfg\n",
        "  !python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy --gpu-id 0\n",
        "\n",
        "def import_best_model(google_drive_folder_path):\n",
        "  shutil.copyfile(google_drive_folder_path+\"model-best.zip\", \"/content/model-best.zip\")\n",
        "\n",
        "def archive_best_model_in_google_drive(google_folder_path):\n",
        "  shutil.make_archive(google_folder_path+\"model-best\", 'zip', \"/content/model-best\")\n",
        "\n",
        "def train_and_load_best_model(training_data,nlp,google_drive_folder_path): \n",
        "  is_nlp_ready = True \n",
        "\n",
        "  try:\n",
        "    is_GPU_on_colab = is_GPU_on() \n",
        "    print(\"is_GPU_on\",is_GPU_on_colab)\n",
        "    if is_GPU_on == True: \n",
        "      create_doc_bin(training_data,nlp)\n",
        "\n",
        "      #train the model \n",
        "      import_base_config_file(google_drive_folder_path)\n",
        "\n",
        "      #trains the model.\n",
        "      train_model() \n",
        "\n",
        "      #archive the best model to Google Drive. \n",
        "      archive_best_model_in_google_drive(google_drive_folder_path) \n",
        "    \n",
        "    if is_GPU_on == False: \n",
        "      import_best_model(google_drive_folder_path)\n",
        "      extract_model_best_from_archive()\n",
        "    \n",
        "    #load the best model\n",
        "    nlp_ner = spacy.load(\"model-best\") \n",
        "  except Exception as e:\n",
        "    return False, \"\"\n",
        "\n",
        "  return is_nlp_ready, nlp_ner\n",
        "\n",
        "\n",
        "def load_best_model_from_archive(google_drive_folder_path):\n",
        "  import_best_model(google_drive_folder_path)\n",
        "  extract_model_best_from_archive()\n",
        "  nlp_ner = spacy.load(\"model-best\") \n",
        "  return True, nlp_ner\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_training_data(training_data,new_tweets,all_birds_name):\n",
        "  \n",
        "  for tweet in new_tweets:\n",
        "    tweet_bird_found = False \n",
        "    print(\"------------***********\")\n",
        "    print(\"------------***********\")\n",
        "    print(tweet)\n",
        "    print(\"------------***********\")\n",
        "\n",
        "    print(\"Labelling work:\")\n",
        "\n",
        "    for bird in all_birds_name:\n",
        "      if tweet.find(bird.strip())>-1:\n",
        "        print(\"From rule matching:\")\n",
        "        print(bird, tweet.find(bird), tweet.find(bird)+len(bird))\n",
        "        training_data[\"annotations\"].append({'text': tweet, 'entities': [(tweet.find(bird), tweet.find(bird)+len(bird), 'BIRDNAME')]})\n",
        "        tweet_bird_found = True  \n",
        "        \n",
        "    \n",
        "    if tweet_bird_found == False :\n",
        "        doc = nlp_ner(tweet)\n",
        "        suggestion = str(doc.ents).replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\")\n",
        "        print(\"Suggestion from NER model: \"+suggestion)\n",
        "        birds_input = input(\"Birds,:\").split(\",\")\n",
        "        if birds_input != \"-\":\n",
        "          for bird_ in birds_input: \n",
        "            bird_ = bird_.strip()\n",
        "            print(bird_, tweet.find(bird_),tweet.find(bird_)+len(bird_))\n",
        "            training_data[\"annotations\"].append({'text': tweet, 'entities': [(tweet.find(bird_), tweet.find(bird_)+len(bird_), 'BIRDNAME')]})\n",
        "            \n",
        "    print(\"---\")\n",
        "  return training_data "
      ],
      "metadata": {
        "id": "kCw6S9xKYE3S"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Program - 1\n",
        "\n",
        "Run this only once.\n",
        "\n",
        "Note:\n",
        "\n",
        "\n",
        "*   Make sure you've chosen to use GPU.\n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "b4uC4koxN0y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initialisation() \n",
        "import spacy \n",
        "\n",
        "#what is the search term?\n",
        "search_word = what_search_term() \n",
        "print(search_word)\n",
        "\n",
        "#connect to google drive\n",
        "connect_to_google_drive()\n",
        "\n",
        "#connect to twitter api. \n",
        "twitter_api_obj = create_twitter_app_obj() \n",
        "\n",
        "#get Google Drive folder path\n",
        "google_drive_folder_path = get_google_drive_folder_path() \n",
        "print(google_drive_folder_path)\n",
        "\n",
        "#get since_id based on the search term\n",
        "since_id = get_since_id(google_drive_folder_path,search_word) \n",
        "#print(since_id)\n",
        "\n",
        "#load all birds list \n",
        "all_birds = load_all_birds_list(google_drive_folder_path)\n",
        "\n",
        "#load training data\n",
        "training_data = load_training_data(google_drive_folder_path) \n",
        "\n",
        "#Set up Model Training. \n",
        "# PS: GPU needed. \n",
        "nlp = load_nlp_model_() #this is spacy stuff. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_fTKxm6tU6K",
        "outputId": "20a1aa1f-7d29-4127-bc04-8c3d7cca4567"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "2022-08-31 05:31:02.811243: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy[transformers] in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.10.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.4.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (4.1.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (4.64.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.23.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.4.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (57.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.6.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.9.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.0.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (21.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (8.1.0)\n",
            "Requirement already satisfied: spacy-transformers<1.2.0,>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.1.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy[transformers]) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy[transformers]) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy[transformers]) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2.10)\n",
            "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (0.8.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (1.12.1+cu113)\n",
            "Requirement already satisfied: transformers<4.22.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (4.21.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy[transformers]) (0.7.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (4.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (0.9.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy[transformers]) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy[transformers]) (2.0.1)\n",
            "indiAves\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/IndiAves/\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_GPU_on_colab = is_GPU_on()\n",
        "#is_nlp_ready,nlp_ner = train_and_load_best_model(training_data,nlp,google_drive_folder_path)\n",
        "is_nlp_ready,nlp_ner = load_best_model_from_archive(google_drive_folder_path) #for quicker work"
      ],
      "metadata": {
        "id": "bBDL_1pilN0a"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Program - 2\n",
        "\n",
        "Keep re-running this!"
      ],
      "metadata": {
        "id": "jzz4OUx3OApL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fetch tweets\n",
        "since_id = add_to_database(twitter_api_obj,search_word, google_drive_folder_path, since_id) \n",
        "new_tweets_df = pd.read_csv(\"/content/temp_.csv\", names=[\"created_at\", \"tweet_id\", \"user\", \"location\", \"tweet\", \"media_url\", \"hashtags\"])\n",
        "new_tweets = preprocess_tweets_arr_batch(new_tweets_df[\"tweet\"].tolist())\n",
        "all_birds_name = all_birds[\"bird_name\"].tolist() \n",
        "\n",
        "#Update training data. ###NEEDS USER INTERVENTION. \n",
        "update_training_data(training_data,new_tweets,all_birds_name)\n",
        "backup_training_data = training_data \n",
        "\n",
        "#Exports training data \n",
        "export_training_data(training_data,google_drive_folder_path)\n",
        "\n",
        "#Update since_id\n",
        "update_since_id(since_id,google_drive_folder_path,search_word)\n",
        "\n",
        "#delete temp_.csv \n",
        "os.remove(\"/content/temp_.csv\")"
      ],
      "metadata": {
        "id": "CbuzT4gaN_tg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31fd2f3d-3dbf-401a-d4f9-9ff17944e1b5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-31 05:40:18.495921 56 tweets retrieved.\n",
            "------------***********\n",
            "------------***********\n",
            "not too comfortable with mobile photography but with birds like parrots you dont have to wait for too long for the action to begin\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "for theme the common castor butterfly\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "my passion for started from my garden during the pandemic this one specially for my twitter friends\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "tried macro photography for the theme by\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "lesser flameback september bedroom window birding\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: lesser flameback\n",
            "Birds,:lesser flameback\n",
            "lesser flameback 0 16\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "a streaky photo of a female streaked weaver\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "streaked weaver 28 43\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "here are a few clicks the peacock was shot with a telephoto accessory\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:peacock\n",
            "peacock 26 33\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "my office is in ground floor of a narrow lane one evening at pm i saw something flying overhead i saw a barn owl perching i went to a nearby building st floor and took this shot kolkata samsung s21 ultra\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: barn owl\n",
            "Birds,:barn owl\n",
            "barn owl 104 112\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "blue whistling thrush\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "blue whistling thrush 0 21\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "indian thick knee stone curlew\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: indian thick knee\n",
            "Birds,:indian thick knee\n",
            "indian thick knee 0 17\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "for the theme by oriental dwarf kingfisher a pic that taken\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "oriental dwarf kingfisher 17 42\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "purple sunbird looks like a juvenile samsung s20 ultra may june kolkata\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "purple sunbird 0 14\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "a very good theme by\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "spotted owlet st picddholkata samsung s21 ultra\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "spotted owl 0 11\n",
            "From rule matching:\n",
            "spotted owlet 0 13\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "common myna in my garden shot with iphone pro max\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "common myna 0 11\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "there is always a rebel back bencher\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "rossy morning beautiful people shubh wednesday\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: rossy\n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "one eyed character\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "its amazing how can capture just a split second of something exquisite is such an apt theme\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "barn owl and lesser flameback woodpecker clicked\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: barn owl lesser flameback woodpecker\n",
            "Birds,:barn owl,lesser flameback woodpecker\n",
            "barn owl 0 8\n",
            "lesser flameback woodpecker 13 40\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "birds of delhi\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "i am so glad i could spot this tiny indian white eye\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "indian white eye 36 52\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "delight red cheeked cordon bleau ciao\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: red cheeked cordon bleau\n",
            "Birds,:red cheeked cordon bleau\n",
            "red cheeked cordon bleau 8 32\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "my daily birding location\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "during my first year of birdwatching my love for hoopoes gave me a burn scar and a traffic ticket the next year i almost wrecked my car and broke my neck blinded by love i kept finding myself in bizarre situations heres my story\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:hoopoe\n",
            "hoopoe 49 55\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "good morning ultramarine flycatcher female\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "ultramarine flycatcher 13 35\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "you cant go wrong in bhigwan from dawn to dusk with mobile or with a dslr the cormorant and heron tree during the boat ride\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:cormorant, heron\n",
            "cormorant 78 87\n",
            "heron 92 97\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "green bee eater with catch nikon d3500 300mm\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "green bee eater 0 15\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "angry red wattled lapwing nikon d3500 300mm\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "red wattled lapwing 6 25\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "a sunbird nearby the flowers palakkad kerala aug\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: sunbird\n",
            "Birds,:sunbird\n",
            "sunbird 2 9\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "the busy taking a break while building his new home\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "the moment we sighted this indian nighjar by the roadside in the headlights i knew the zoom lens wasnt going to help a few meters of flat crawl and was close enough to get it\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: indian\n",
            "Birds,:indian nighjar\n",
            "indian nighjar 27 41\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "yellow billed babbler the original angry bird\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "yellow billed babbler 0 21\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "on my windowsill jungle babbler couple\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "jungle babbler 17 31\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "somewhere in the forests of telangana\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "if looks could kill spotted owlet spotted at shivamogga\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "spotted owl 20 31\n",
            "From rule matching:\n",
            "spotted owlet 20 33\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "intresting theme for midweek and here is my entry crested serpant eagle and elephants from\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:crested serpant eagle\n",
            "crested serpant eagle 50 71\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "a pre nuptial gift from her to him red munia strawberry finch\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: red munia\n",
            "Birds,:red munia, strawberry finch\n",
            "red munia 35 44\n",
            "strawberry finch 45 61\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "another busy day for the ants\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "green bee eater during lockdown april samsung s10 plus kolkata\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "green bee eater 0 15\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "for theme indian pitta pitta brachyura\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "indian pitta 10 22\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "shot on my samsung s10 plus with slow motion feature jan feb\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "date and time round minutes back location my home in kolkata window birding samsung s22 ultra\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "rose ringed parakeet couple kissing scene samsung s9 plus location kolkata\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "rose ringed parakeet 0 20\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "in an age where mobile devices are marketed because of their camera specs is such an apt theme\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "red whiskered bulbul may ooty samsung s10 plus\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "red whiskered bulbul 0 20\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "day moth fodina sp\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "chital or spotted deer shot on bangalore ooty highway may samsung s10 plus\n",
            "------------***********\n",
            "Labelling work:\n",
            "Suggestion from NER model: \n",
            "Birds,:-\n",
            "- -1 0\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "thick billed green pigeon female march samsung s21 ultra location kolkata\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "thick billed green pigeon 0 25\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "white throated kingfisher state bird of west bengal location kolkata date april samsung s21 ultra\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "white throated kingfisher 0 25\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "blue throated barbet samsung s21 ultra march location kolkata\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "blue throated barbet 0 20\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "blue throated barbet location kolkata march samsung s21 ultra\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "blue throated barbet 0 20\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "mobile shot of a rose ringed parakeet location kolkata april\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "rose ringed parakeet 17 37\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "a napping yellow crowned night heron appears to be dreaming about an egret which is foraging nearby marine nature study area oceanside new york 2022 07 28\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "yellow crowned night heron 10 36\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "few pages from my own jungle book clicked in indian roller white throated kingfisher rufous treepie spider weaving a gossamer web\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "indian roller 45 58\n",
            "From rule matching:\n",
            "rufous treepie 85 99\n",
            "From rule matching:\n",
            "white throated kingfisher 59 84\n",
            "---\n",
            "------------***********\n",
            "------------***********\n",
            "defending territory from a lazuli bunting family\n",
            "------------***********\n",
            "Labelling work:\n",
            "From rule matching:\n",
            "lazuli bunting 27 41\n",
            "---\n",
            "2 examples of training data saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stand alone test."
      ],
      "metadata": {
        "id": "vRTJG1GfOTzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"this is a preprocessed text and it should find spotted dove\"\n",
        "doc = nlp_ner(sentence)\n",
        "print(doc.ents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD3JN5VuKzsm",
        "outputId": "2275d20a-d626-4cf3-e144-49488ec07f2c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(spotted dove,)\n"
          ]
        }
      ]
    }
  ]
}